<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cloudera CDH 6.3.2 on Debuntarium</title>
    <link>http://localhost:1313/tags/cloudera-cdh-6.3.2/</link>
    <description>Recent content in Cloudera CDH 6.3.2 on Debuntarium</description>
    <generator>Hugo</generator>
    <language>ru-ru</language>
    <lastBuildDate>Mon, 06 Dec 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/cloudera-cdh-6.3.2/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Сборка Apache Atlas 2.2.0 для Cloudera CDH 6.3.2</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/sborka-apache-atlas-2.2.0-dlya-cloudera-cdh-6.3.2/</link>
      <pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/sborka-apache-atlas-2.2.0-dlya-cloudera-cdh-6.3.2/</guid>
      <description>⚠ Важное сообщение. Сборка проходит успешно только после комментирования строк с константами MATERIALIZED_VIEW. В исходниках предыдущей версии Apache Atlas 2.1.0 такие константы не применялись. MATERIALIZED_VIEW относится к таблицам Hive 3.x версии, тогда как в CDH 6.3.2 используется Hive 2.1.1.&#xA;⚠ В этой сборке предусмотривается возможность работы Apache Atlas с Elasticsearch 6.8.20, в расчёте на дальнейшее внедрение Amundsen. В мануале по Amundsen указано, что поддерживается работа только с Elasticsearch 6.x.</description>
    </item>
    <item>
      <title>02. Установка Cloudera Manager 6.3.1</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/ustanovka-cloudera-manager-6-3.1/</link>
      <pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/ustanovka-cloudera-manager-6-3.1/</guid>
      <description>2021-06-16&#xA;1. Введение Номер последней версии Cloudera Manager, которая может работать без лицензии, это 6.3.1.&#xA;После преднастроек и проверок приступаем к установке Cloudera Manager на один из хостов будущего кластера. То есть сначала установим Cloudera Manager на машину управления, с помощью которого, позже, установим сервисы Zookeeper, HDFS, YARN, и далее по списку.&#xA;Все операции выполняем на командной машине с помощью ансибла из ранее подготовленного каталога hadoop, где созданы все необходимые файлы.</description>
    </item>
    <item>
      <title>03. Установка основных компонентов Cloudera CDH 6.3.2</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/ustanovka-osnovnykh-komponentov-cloudera-cdh-6.3.2/</link>
      <pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/ustanovka-osnovnykh-komponentov-cloudera-cdh-6.3.2/</guid>
      <description>2021-06-16&#xA;Может быть будет удобнее, если установить основные пакеты для Hadoop&amp;rsquo;а вручную, как описано на странице Ручная установка набора Cloudera-пакетов.&#xA;Welcome После входа на веб-страницу Cloudera Manager http://prod-mgm01p.example.org:7180/ соглашаемся с пользовательским соглашением и выбираем бесплатную лицензию Cloudera Express.&#xA;Cluster Basics Указываем имя кластера. Это имя не имеет никаких зависимостей в работе кластера и в любой момент может быть изменено. Cloudera Manager позволяет управлять несколькими кластерами, каждый из которых имеет своё имя.</description>
    </item>
    <item>
      <title>03. Установка основных компонентов Cloudera CDH 6.3.2</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/ustanovka-osnovnykh-komponentov-cloudera-cdh-6.3.2/</link>
      <pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/ustanovka-osnovnykh-komponentov-cloudera-cdh-6.3.2/</guid>
      <description>2021-06-16&#xA;Может быть будет удобнее, если установить основные пакеты для Hadoop&amp;rsquo;а вручную, как описано на странице Ручная установка набора Cloudera-пакетов.&#xA;Welcome После входа на веб-страницу Cloudera Manager http://prod-mgm01p.example.org:7180/ соглашаемся с пользовательским соглашением и выбираем бесплатную лицензию Cloudera Express.&#xA;Cluster Basics Указываем имя кластера. Это имя не имеет никаких зависимостей в работе кластера и в любой момент может быть изменено. Cloudera Manager позволяет управлять несколькими кластерами, каждый из которых имеет своё имя.</description>
    </item>
    <item>
      <title>04. После установки основных компонентов</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/posle-ustanovki-osnovnykh-komponentov/</link>
      <pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/posle-ustanovki-osnovnykh-komponentov/</guid>
      <description>2021-06-16&#xA;Настройка каталогов для логгирования В центральном окне Cloudera Web UI выбираем раздел Log Directories, где изменяем все &amp;lsquo;/var/log&amp;rsquo; на &amp;lsquo;/data/log&amp;rsquo;: Также и для каждого Cloudera-сервиса заходим в конфигурацию и ищём параметры по признаку &amp;lsquo;/var&amp;rsquo;, которые и меняем на &amp;lsquo;/data/log&amp;rsquo;.&#xA;Применяем изменения для Cloudera Management и для кластера.&#xA;Выполняем предложения Cloudera Рассматриваем предложения Cloudera Management Console и исправляем ситуацию. Стараемся, по возможности, добиться полностью &amp;ldquo;зелёного&amp;rdquo; состояния кластера, но часто это невозможно из-за, например, недостатка ресурсов выделенных для инициализации кластера.</description>
    </item>
    <item>
      <title>01. Подготовительные работы для установки Atlas&#39;а</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/podgotovitelnyye-raboty-dlya-ustanovki-atlas/</link>
      <pubDate>Wed, 03 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/podgotovitelnyye-raboty-dlya-ustanovki-atlas/</guid>
      <description>Везде, где выполняется работа с керберизированными сервисами, помним о предварительном получении Kerberos-билета, если таковой не был получен ранее.&#xA;Подавляющее число операций производим на Atlas-машине, иначе специально указывается иное.&#xA;1. Введение выделенного для Atlas хоста в домен Выполняется с помощью стандартных процедур.&#xA;2. Добавление хоста к Hadoop-кластеру Выполняется с помощью стандартных процедур.&#xA;3. Добавление учётных записей 3.1. Добавление локальной УЗ &amp;lsquo;atlas&amp;rsquo; На все машины кластера добавляем локальную УЗ &amp;lsquo;atlas&amp;rsquo;.&#xA;sudo useradd -r -s /sbin/nologin -d /opt/atlas -M atlas sudo usermod -aG hadoop atlas 3.</description>
    </item>
    <item>
      <title>02. Подготовка служб Hadoop-кластера к развёртыванию Atlas&#39;а</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/podgotovka-sluzhb-hadoop-klastera-k-razvortyvaniyu-atlas/</link>
      <pubDate>Wed, 03 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/podgotovka-sluzhb-hadoop-klastera-k-razvortyvaniyu-atlas/</guid>
      <description>2021-08-10 – 2021-11-03&#xA;1. Apache HBase Apache HBase используется Atlas&amp;rsquo;ом для хранения своей Janus базы данных. Бла-бла-бла&amp;hellip;&#xA;1.1. Настройка Apache HBase Настройка HBase в тестовом кластере была выполнена в соответствии с инструкцией 16. HBase. Установка и настройка.&#xA;1.2. Создание необходимых таблиц в HBase 1.2.1. На Atlas-машине, или на любой машине с установленной ролью &amp;lsquo;HBase Gateway&amp;rsquo;, создаём необходимые таблицы и даём на них все права для УЗ &amp;lsquo;atlas&amp;rsquo;:&#xA;# Названия таблиц по умолчанию: TABLE1=&amp;#34;apache_atlas_entity_audit&amp;#34; TABLE2=&amp;#34;apache_atlas_janus&amp;#34; echo &amp;#34;create &amp;#39;${TABLE1}&amp;#39;, &amp;#39;dt&amp;#39;; grant &amp;#39;atlas&amp;#39;, &amp;#39;RWXCA&amp;#39;, &amp;#39;${TABLE1}&amp;#39;&amp;#34; | hbase shell echo &amp;#34;create &amp;#39;${TABLE2}&amp;#39;, &amp;#39;s&amp;#39;; grant &amp;#39;atlas&amp;#39;, &amp;#39;RWXCA&amp;#39;, &amp;#39;${TABLE2}&amp;#39;&amp;#34; | hbase shell В случае внесения УЗ &amp;lsquo;atlas&amp;rsquo; в параметр &amp;lsquo;hbase.</description>
    </item>
    <item>
      <title>03. Выбор и подготовка поискового движка для использования Atlas&#39;ом</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/vybor-i-podgotovka-poiskovogo-dvizhka-dlya-ispolzovaniya-atlas/</link>
      <pubDate>Wed, 03 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/vybor-i-podgotovka-poiskovogo-dvizhka-dlya-ispolzovaniya-atlas/</guid>
      <description>2021-08-10 – 2021-11-03&#xA;1. Выбор поискового движка: Apache Solr or Elasticsearch 1.1. Стандартно используется Apache Solr.&#xA;1.2. В расчёте на дальнейшую установку Amundsen&amp;rsquo;а, необходимо выбрать ElsaticSarch. На данный момент находится в разработке.&#xA;Я попробую установить оба Index-сервиса с двумя экземплярами Atlas&amp;rsquo;а. Первый экземпляр Atlas&amp;rsquo;а будет использовать Apache Solr, а второй экземпляр Atlas&amp;rsquo;а, соответственно, Elasticsearch. Мысли под запись: УЗ &amp;lsquo;atlas&amp;rsquo;, как локальная, так и сервисная УЗ &amp;lsquo;atlas/_HOST&amp;rsquo;, будут использоваться обоими экземплярами Atlas&amp;rsquo;а.</description>
    </item>
    <item>
      <title>04. Распаковка и настройка Apache Atlas</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/raspakovka-i-nastroyka-apache-atlas/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/raspakovka-i-nastroyka-apache-atlas/</guid>
      <description>2021-10-20 – 2021-11-02&#xA;Везде, где выполняется работа с керберизированными сервисами, помним о предварительном получении Kerberos-билета, если таковой не был получен ранее. Подавляющее число операций производим на Atlas-машине, иначе специально указывается иное.&#xA;1. Скачивание и распаковка собранного приложения Apache Atlas Стандартное размещение Atlas&amp;rsquo;а находится в каталоге /opt/atlas. Для удобства работы с множеством версий, мы разместим эту и последующие сборки Atlas&amp;rsquo;а, каждую в своём каталоге, например /opt/apache-atlas-2.2.0. После чего создадим линк /opt/atlas для текущей актуальной сборки.</description>
    </item>
    <item>
      <title>05. 🎣 Заброс Hook&#39;а в Apache Hive</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/zabros-hook-v-apache-hive/</link>
      <pubDate>Mon, 30 Aug 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/zabros-hook-v-apache-hive/</guid>
      <description>2021-08-30&#xA;1.Введение Механизм работы передачи информации об изменениях в Apache Hive в Apache Atlas очень прост. В Apache Hive добавляется Hook, то есть java-библиотека, которая будет отправлять сообщения в Apache Kafka при любых? изменениях в Apache Hive. Apache Atlas, после получения этих сообщений, приводит свой багаж знаний в соответствии с информацией из сообщений.&#xA;2. Создание Atlas-папки на хостах с ролью &amp;lsquo;HiveServer2&amp;rsquo; 2.1. На хостах с ролью &amp;lsquo;HiveServer2&amp;rsquo; создаём atlas-каталоги и скачиваем с Nexus&amp;rsquo;а необходимый файл:</description>
    </item>
    <item>
      <title>Сборка Apache Atlas 2.1.0 для Cloudera CDH 6.3.2 (устарело)</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/sborka-apache-atlas-2-1-0-dlya-cloudera-cdh-6-3-2/</link>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/sborka-apache-atlas-2-1-0-dlya-cloudera-cdh-6-3-2/</guid>
      <description>2021-08-05&#xA;1. Подготовка хоста Сначала хост добавляем в Cloudera-кластер, чтобы при установке Cloudera CDH были корректно добавлены локальные аккаунты и группы. В процессе добавления в кластер, перед включением TLS-аутентификации для Cloudera Agent, добавляем хост в домен. На хост установлены шлюзы для YARN, HBase, Hive, Kafka, Solr. 2. Установка Maven Сначала устанавливаем maven 3.0.5-17.el7 из стандартных репо для CentOS7:&#xA;$ sudo yum install maven ... Dependencies Resolved ===================================================================================================================== Package Arch Version Repository Size ===================================================================================================================== Installing: maven noarch 3.</description>
    </item>
    <item>
      <title>Блокирование доступа внешних программ к Hive metastore</title>
      <link>http://localhost:1313/n/blokirovanie-dostupa-vneshnih-programm-k-hive-metastore/</link>
      <pubDate>Mon, 19 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/n/blokirovanie-dostupa-vneshnih-programm-k-hive-metastore/</guid>
      <description>2021-07-19&#xA;Before Enabling the Sentry Service&#xA;Могут быть указаны дополнительные пользовательские группы.</description>
    </item>
    <item>
      <title>10. Настройка TLS для Cloudera Manager Server и его агентов</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/nastroyka-tls-dlya-cloudera-manager-server-i-yego-agentov/</link>
      <pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/nastroyka-tls-dlya-cloudera-manager-server-i-yego-agentov/</guid>
      <description>Использованные материалы Manually Configuring TLS Encryption for Cloudera Manager Manually Configuring TLS Encryption on the Agent Listening Port Вступление Когда вы настраиваете аутентификацию и авторизацию в кластере, Cloudera Manager Server отправляет различную конфиденциальную информацию по сети на узлы кластера, например, таблицы ключей Kerberos и файлы конфигурации, содержащие пароли. Чтобы защитить эту передачу, необходимо настроить TLS-шифрование между Cloudera Manager Server и всеми узлами кластера.&#xA;Шифрование TLS также используется для защиты клиентских подключений к административному интерфейсу Cloudera Manager с помощью HTTPS.</description>
    </item>
    <item>
      <title>Получение keytab-файла для сервисного принципала</title>
      <link>http://localhost:1313/n/poluchenie-keytab-faila-dlya-servisnogo-principala/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/n/poluchenie-keytab-faila-dlya-servisnogo-principala/</guid>
      <description>2021-04-01&#xA;Ссылки: https://www.freeipa.org/page/V4/Keytab_Retrieval_Management https://www.freeipa.org/page/V4/Keytab_Retrieval&#xA;Например, находясь на узле со службой, для которой нам необходимо получить keytab, сначала, если ещё не получили, то получаем тикет:&#xA;$ kinit $USER Назначаем себе право получения таблицу ключей:&#xA;$ ipa service-allow-retrieve-keytab hbase/$(hostname) --users=$USER Имя учётной записи: hbase/prod-hbr01p.example.org@EXAMPLE.ORG Псевдоним учётной записи: hbase/prod-hbr01p.example.org@EXAMPLE.ORG Managed by: prod-hbr01p.example.org Пользователи, которым разрешено получать таблицу ключей: eugene Получаем таблицу ключей и сохраняем её в файле:&#xA;$ ipa-getkeytab -r -p hbase/$(hostname) -k ~/keytabs/hbase_$(hostname -s).</description>
    </item>
    <item>
      <title>Настройка LDAP-аутентификации Hive в керберизированном Cloudera CDH 6.3.2</title>
      <link>http://localhost:1313/n/nastroika-ldap-autentifikacii-v-kerberizirovannom-cloudera-hive/</link>
      <pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/n/nastroika-ldap-autentifikacii-v-kerberizirovannom-cloudera-hive/</guid>
      <description>Ссылки HiveServer2 Security Configuration&#xA;Настройка LDAP-аутентификации На странице Configurations для Hive, используем фильтр ldap, и:&#xA;Включаем LDAP Enable LDAP Authentication Hive (Service-Wide): ☑ Указываем адрес LDAP-сервера LDAP URL hive.server2.authentication.ldap.url: ldaps://ldap1.example.org ldaps://ldap2.example.org ldaps://ldap3.example.org Указываем контейнер поиска пользователей LDAP BaseDN hive.server2.authentication.ldap.baseDN: cn=users,cn=accounts,dc=example,dc=org </description>
    </item>
    <item>
      <title>Перенос кластера Cloudera CDH 6.3.2 в другой vlan</title>
      <link>http://localhost:1313/n/perenos-klastera-cloudera-cdh-6-3-2-v-drugoi-vlan/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/n/perenos-klastera-cloudera-cdh-6-3-2-v-drugoi-vlan/</guid>
      <description>2020-10-21&#xA;Работа производилась на Cloudera CDH 6.3.2. Используется встроенный PostgreSQL.&#xA;Остановить кластер. Остановить Cloudera Service Management. На всех хостах остановить агенты: systemctl stop cloudera-scm-agent systemctl disable cloudera-scm-agent На управляющем хосте остановить службы Cloudera Server и встроенный PostgreSQL: systemctl stop cloudera-scm-server systemctl disable cloudera-scm-server systemctl stop cloudera-scm-server-db systemctl disable cloudera-scm-server-db На всех узлах привести записи в /etc/hosts к актуальному состоянию. Если кластер в домене IPA, а автоматическое обновление DNS-записей не произошло, то добавить в файл /etc/sssd/sssd.</description>
    </item>
    <item>
      <title>Disabling Hive CLI</title>
      <link>http://localhost:1313/n/disabling-hive-cli/</link>
      <pubDate>Mon, 05 Oct 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/n/disabling-hive-cli/</guid>
      <description>Перед выполнением этой инструкции, необходимо ознакомиться с Блокирование доступа внешних программ к Hive metastore, где описано более централизованный способ блокирования доступа к Metastore Hive.&#xA;После активации Cloudera Sentry, необходимо предотвратить возможность использования консольной утилиты hive пользователями. Вместо hive, пользователи должны использовать утилиту beeline.&#xA;Каталог HIVE_HOME можно найти из-под root командой:&#xA;$ sudo hive -e &amp;#39;!env&amp;#39;|grep HIVE_HOME HIVE_HOME=/usr/lib/hive Таким образом, отключение Hive CLI производим следующими командами:&#xA;HIVE_HOME=$(hive -e &amp;#39;!env&amp;#39;|grep HIVE_HOME|awk -F&amp;#39;=&amp;#39; &amp;#39;{print $2}&amp;#39;) setfacl -m u:hive:rx $HIVE_HOME/bin/hive chmod 754 $HIVE_HOME/bin/hive Разъяснение: Hive не будет стартовать, если не оставить ему доступ к этому файлу.</description>
    </item>
    <item>
      <title>Исправление застрявшего статуса у роли в Cloudera CDH</title>
      <link>http://localhost:1313/n/ispravlenie-zastryavshego-statusa-u-roli-v-cloudera-hadoop/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/n/ispravlenie-zastryavshego-statusa-u-roli-v-cloudera-hadoop/</guid>
      <description>2020-09-26&#xA;Из-за поспешной перезагрузки агентов или management service, статус роли, которую перегружали, может застрять в RUNNING или STOPPING. В результате, с ролью ничего нельзя сделать.&#xA;Исправление Заходим в клаудеровскую базу данных PostgreSQL.&#xA;В случае использования встроенной БД, находим автоматический созданный пароль так:&#xA;cat /var/lib/cloudera-scm-server-db/data/generated_password.txt MnPwGeWaip Заходим в CLI:&#xA;psql -U cloudera-scm -p 7432 -h localhost -d postgres Password for user cloudera-scm: MnPwGeWaip Переходим в базу scm и выполняем поиск застрявшего статуса, например STOPPING, и его замену:</description>
    </item>
    <item>
      <title>06. 🎣 Заброс Hook&#39;а в Apache HBase</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/zabros-hook-v-apache-hbase/</link>
      <pubDate>Fri, 22 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/zabros-hook-v-apache-hbase/</guid>
      <description>2021-08-30 / 2021-10-22&#xA;1.Введение Механизм работы передачи информации об изменениях в Apache Hive в Apache Atlas очень прост. В Apache Hive добавляется Hook, то есть java-библиотека, которая будет отправлять сообщения в Apache Kafka при любых? изменениях в Apache Hive. Apache Atlas, после получения этих сообщений, приводит свой багаж знаний в соответствии с информацией из сообщений.&#xA;2. Создание Atlas-папки на хостах с ролью &amp;lsquo;HBase Master&amp;rsquo; 2.1. На хостах с ролью &amp;lsquo;HBase Master&amp;rsquo; создаём atlas-каталоги и скачиваем с Nexus&amp;rsquo;а необходимый файл:</description>
    </item>
    <item>
      <title>11. Настройка TLS для HDFS и YARN</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/nastroyka-tls-dlya-hdfs-i-yarn/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/nastroyka-tls-dlya-hdfs-i-yarn/</guid>
      <description>Использованные материалы Manually Configuring TLS/SSL Encryption for CDH Services&#xA;Вступление Помимо настройки кластера Cloudera Manager для использования TLS, различные службы CDH, работающие в кластере, также должны быть настроены для использования TLS. Процесс настройки TLS зависит от компонента, поэтому выполните следующие действия, если это необходимо для вашей системы. Однако, прежде чем пытаться настроить TLS, убедитесь, что ваш кластер соответствует предварительным требованиям.&#xA;В общем, все роли на любом узле в кластере могут использовать одни и те же сертификаты, при условии, что сертификаты имеют соответствующий формат (JKS, PEM) и что конфигурация правильно указывает на расположение.</description>
    </item>
    <item>
      <title>07. 🎣 Заброс Hook&#39;а в Spark (в разработке)</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/zabros-hook-v-spark/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/zabros-hook-v-spark/</guid>
      <description>Почитать:&#xA;Как использовать соединитель Apache Atlas для сбора сведений о происхождении данных Spark </description>
    </item>
    <item>
      <title>08. Первый запуск Apache Atlas и его отладка при необходимости</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/pervyy-zapusk-apache-atlas-i-yego-otladka/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/pervyy-zapusk-apache-atlas-i-yego-otladka/</guid>
      <description>2021-11-02&#xA;1. Первый запуск 1.1. Для надёжности выполняем изменение владельца для всего каталога /opt/atlas:&#xA;sudo chown atlas.atlas /opt/atlas/* -R 1.2. Перед первым запуском поменяем уровень логгирования с INFO на DEBUG. Так удобней отслеживать процесс первоначального запуска. В файле /opt/atlas/conf/atlas-log4j.xml приводим соответствующую строку к следующему виду:&#xA;&amp;lt;logger name=&amp;#34;org.apache.atlas&amp;#34; additivity=&amp;#34;false&amp;#34;&amp;gt; &amp;lt;level value=&amp;#34;debug&amp;#34;/&amp;gt; &amp;lt;appender-ref ref=&amp;#34;FILE&amp;#34;/&amp;gt; &amp;lt;/logger&amp;gt; 1.3. Первый запуск Apache Atlas производится командой:&#xA;sudo systemctl enable --now atlas 1.4. Наблюдаем процесс запуска в лог-файле /opt/atlas/logs/application.</description>
    </item>
    <item>
      <title>12. Включение Kerberos в Cloudera CDH 6.3.2</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/vklyucheniye-kerberos-v-cloudera-cdh-6.3.2/</link>
      <pubDate>Thu, 14 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/vklyucheniye-kerberos-v-cloudera-cdh-6.3.2/</guid>
      <description>2021-06-17 – 2021-10-14&#xA;1. Использованные материалы How to Configure Clusters to Use Kerberos for Authentication Configuring Authentication in Cloudera Manager Enabling Kerberos Authentication for CDH Step 1: Install Cloudera Manager and CDH Step 2: Install JCE Policy Files for AES-256 Encryption Step 3: Create the Kerberos Principal for Cloudera Manager Server Step 4: Enabling Kerberos Using the Wizard Step 5: Create the HDFS Superuser Step 6: Get or Create a Kerberos Principal for Each User Account Step 7: Prepare the Cluster for Each User Step 8: Verify that Kerberos Security is Working Step 9: (Optional) Enable Authentication for HTTP Web Consoles for Hadoop Roles Sample Kerberos Configuration Files 2.</description>
    </item>
    <item>
      <title>10. Первоначальный импорт содержимого Hive</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/pervonachalnyy-import-soderzhimogo-hive/</link>
      <pubDate>Sun, 29 Aug 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/pervonachalnyy-import-soderzhimogo-hive/</guid>
      <description>2021-08-29&#xA;Первоначальный импорт содержимого Hive в Atlas производится только один раз, сразу после настройки Atlas Hook&amp;rsquo;а для Hive. Apache Atlas должен быть запущен и слушать &amp;lsquo;atlas.rest.address=https://dev-app111p.test2.lan:21443&amp;rsquo;. После одноразового импорта, дальнейшее соответствие информации между Atlas и Hive производится только на основании сообщений из Kafka.&#xA;Повторное использование ручного импорта не приведёт Атласовскую информацию о содержимом Hive&amp;rsquo;е в их полное соответствие. Те таблицы, которые есть в Atlas&amp;rsquo;е, но отсутствуют в Hive&amp;rsquo;е, не будут удалены из Atals&amp;rsquo;а.</description>
    </item>
    <item>
      <title>11. Первоначальный импорт содержимого HBase</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/pervonachalnyy-import-soderzhimogo-hbase/</link>
      <pubDate>Sun, 29 Aug 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/pervonachalnyy-import-soderzhimogo-hbase/</guid>
      <description>2021-08-29&#xA;Первоначальный импорт содержимого HBase в Atlas производится только один раз, сразу после настройки Atlas Hook&amp;rsquo;а для HBase. Apache Atlas должен быть запущен и слушать &amp;lsquo;atlas.rest.address=https://dev-app111p.test2.lan:21443&amp;rsquo;. После одноразового импорта, дальнейшее соответствие информации между Atlas и HBase производится только на основании сообщений из Kafka.&#xA;Повторное использование ручного импорта не приведёт Атласовскую информацию о содержимом HBase&amp;rsquo;е в их полное соответствие. Те объекты, которые есть в Atlas&amp;rsquo;е, но отсутствуют в HBase&amp;rsquo;е, не будут удалены из Atals&amp;rsquo;а.</description>
    </item>
    <item>
      <title>20. 🔬 Тестирование работоспособности Apache Atlas</title>
      <link>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/testirovaniye-rabotosposobnosti-apache-atlas/</link>
      <pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/apacheatlas/ustanovka-apache-atlas-2.2.0/testirovaniye-rabotosposobnosti-apache-atlas/</guid>
      <description>2021-12-06&#xA;После подключения Apache Atlas&amp;rsquo;а к Hadoop&amp;rsquo;у мы должны удостовериться в работоспособности приложения.&#xA;1. Проверка получения информации из Hive 1.1. На машине с ролью HDFS Gateway, в своём домашнем каталоге создаём csv-файл и загружаем в HDFS:&#xA;TESTFILENAME=&amp;#34;atlas25.csv&amp;#34; cat &amp;lt;&amp;lt; EOF &amp;gt; ${TESTFILENAME} 1,Hive Hook 2,HBase Hook 3,Spark Hook EOF hdfs dfs -put ${TESTFILENAME} 1.2. Есть вероятность что аккаунт hive, которого чуть позже заставим импортировать данные из файла в таблицу, не имеет прав на домашний каталог + созданный файл, поэтому выдаём права:</description>
    </item>
    <item>
      <title>13. Zookeeper. Настройка</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/zookeeper-nastroyka/</link>
      <pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/zookeeper-nastroyka/</guid>
      <description>2021-07-09&#xA;Настройка TLS для ZooKeeper Напомню, что перед включением TLS-настроек для Zookeeper&amp;rsquo;а должен быть включён TLS для «Firehose Debug Server» в Cloudera Manager. Иначе Zookeeper будет работать, но статус ролей перестаёт отображаться корректно и высвечивается ошибка &amp;ldquo;Quorum Membership&amp;rdquo;. В настройках сервиса ZooKeeper, используя фильтр по слову &amp;lsquo;JMX&amp;rsquo;, изменяем следующие параметры: Нажимаем Save Changes. Перезапускаем все зависимые сервисы по приглашению Cloudera Manager Console. Ссылки по теме Получение прав Superuser&amp;rsquo;а в ZooKeeper&amp;rsquo;е Cloudera CDH 6.</description>
    </item>
    <item>
      <title>14. HDFS. Настройка</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/hdfs-nastroyka/</link>
      <pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/hdfs-nastroyka/</guid>
      <description>2021-07-09 – 2021-10-15&#xA;1. Enable High Availability Enabling HDFS HA&#xA;В настройках сервиса HDFS, используя фильтр по слову «dfs.journalnode.edits.dir», изменяем следующий параметр: Нажимаем Save Changes. На странице службы HDFS, через кнопку Actions, запускаем wizard включения HA: Getting Started. Задаём уникальное имя для Nameservice: Assign Roles. JournalNodes должны работать на хостах с такими же hardware specification, как NameNodes. Cloudera рекомендует поместить две JournalNode на те же хосты с NameNodes, а третий JournalNode на хост с похожими ресурсами, таким как JobTracker.</description>
    </item>
    <item>
      <title>15. YARN. Настройка</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/yarn-nastroyka/</link>
      <pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/yarn-nastroyka/</guid>
      <description>2021-07-09&#xA;1. Перенастройка размещения log&amp;rsquo;ов В настройках YARN, используя фильтр &amp;lsquo;/var/log&amp;rsquo;, изменяем только следующие параметры, добавляя имя каталога &amp;lsquo;/data&amp;rsquo; вместо &amp;lsquo;/var&amp;rsquo;: Нажимаем Save Changes. 2. Настройка ACL Managing YARN ACLs&#xA;Во FreeIPA добавляем группу &amp;rsquo;test1_yarn_admins&amp;rsquo;: ADM_USER=&amp;#39;eugene&amp;#39; \ ADM_PASS=&amp;#39;JL9d]qtw$p=2=M2K=~z?|EU,&amp;#39; \ CL_NAME=&amp;#34;TEST1&amp;#34; # UPPERCASE \ CL_NAME_L=${CL_NAME,,} # lowercase ansible mgm -i cluster.inv -m shell -a &amp;#34;echo &amp;#39;${ADM_PASS}&amp;#39; | kinit ${ADM_USER} &amp;amp;&amp;amp; \ ipa group-add --desc=&amp;#39;YARN admins for cluster ${CL_NAME}&amp;#39; ${CL_NAME_L}_yarn_admins&amp;#34; В настройках YARN, используя фильтр «acl», изменяем только следующие параметры: В настройках YARN, используя фильтр «Admin Users Applications List», изменяем только следующие параметры: 3.</description>
    </item>
    <item>
      <title>16. HBase. Установка и настройка</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/hbase-ustanovka-i-nastroyka/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/hbase-ustanovka-i-nastroyka/</guid>
      <description>Использованные материалы Manually Configuring TLS/SSL Encryption for CDH Services 1. Добавление сервиса HBase В консоли Cloudera Manager в меню выбираем «Add Service»: Выбираем HBase. Распределяем роли. Хосты с именем hbr под HBase Region Servers&amp;hellip; На следующем шаге оставляем настройки без изменений: Ждём добавления сервиса в кластер. После успешного завершения процесса заканчиваем мастер нажатием на &amp;lsquo;Finish&amp;rsquo;. Перезапускаем все зависимые сервисы по приглашению Cloudera Manager Console. 2. Перенастройка размещения log&amp;rsquo;ов В настройках HBase, используя фильтр &amp;lsquo;/var/&amp;rsquo;, изменяем следующие параметры, добавляя &amp;lsquo;/data&amp;rsquo; вместо &amp;lsquo;/var&amp;rsquo;: Нажимаем Save Change.</description>
    </item>
    <item>
      <title>17. Spark. Установка и настройка</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/spark-ustanovka-i-nastroyka/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/spark-ustanovka-i-nastroyka/</guid>
      <description>Использованные материалы Manually Configuring TLS/SSL Encryption for CDH Services Spark Encryption 1. Добавление сервиса Spark В консоли Cloudera Manager в меню выбираем &amp;lsquo;Add Service&amp;rsquo;: Выбираем Spark. Select Dependencies. Assign Roles. Распределяем роли. History Server размещаем на одном из дополнительных aux узлов, а шлюзы на dn-узлах и других по необходимости: Сразу включаем TLS для роли. Наблюдаем добавление Spark&amp;rsquo;а. Заключительный шаг мастера: Перезапускаем все зависимые сервисы по приглашению Cloudera Manager Console. 2. Перенастройка размещения log&amp;rsquo;ов В настройках Spark, используя фильтр &amp;lsquo;/var/&amp;rsquo;, изменяем только следующие параметры, добавляя имя каталога &amp;lsquo;/data&amp;rsquo; вместо &amp;lsquo;/var&amp;rsquo;: Нажимаем Save Changes.</description>
    </item>
    <item>
      <title>18. Hive. Установка и настройка</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/hive-ustanovka-i-nastroyka/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/hive-ustanovka-i-nastroyka/</guid>
      <description>Использованные материалы Manually Configuring TLS/SSL Encryption for CDH Services Добавление сервиса Hive В консоли Cloudera Manager в меню выбираем &amp;lsquo;Add Service&amp;rsquo;: Выбираем Hive. Выбираем зависимости: Распределяем роли. Рекомендуется устанавливать роли Hive Gateway на узлы кластера с ролью Spark Gateway, иначе Hive-таблицы не будут доступны для Spark&amp;rsquo;а. Настройка базы данных. Так как сейчас используется встроенная база данных, то никаких дополнительных действий не производим, а нажимаем кнопку &amp;lsquo;Test Connection&amp;rsquo;. На шаге Review Changes ничего не меняем: Наблюдаем запуск ролей.</description>
    </item>
    <item>
      <title>19. Sentry. Установка и настройка</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/sentry-ustanovka-i-nastroyka/</link>
      <pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/sentry-ustanovka-i-nastroyka/</guid>
      <description>Добавление сервиса Sentry В консоли Cloudera Manager в меню выбираем &amp;lsquo;Add Service&amp;rsquo;: Выбираем Sentry. Распределяем роли: Настройка базы данных. Так как сейчас используется встроенная база данных, то никаких дополнительных действий не производим, а нажимаем кнопку &amp;lsquo;Test Connection&amp;rsquo;. Наблюдаем запуск ролей. Визард успешно закончен. Перенастройка размещения log&amp;rsquo;ов В настройках Sentry, используя категорию &amp;lsquo;Logs&amp;rsquo;, изменяем следующие параметры, добавляя &amp;lsquo;/data&amp;rsquo; вместо &amp;lsquo;/var&amp;rsquo;: Нажимаем Save Changes. Создание группы администраторов Sentry Добавление группы во FreeIPA. Так как установка кластера производится с машины, домен которой отличен от домена настраиваемых машин, то вновь используем ansible:</description>
    </item>
    <item>
      <title>20. Hue. Установка и настройка</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/hue-ustanovka-i-nastroyka/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/hue-ustanovka-i-nastroyka/</guid>
      <description>Использованные материалы Manually Configuring TLS/SSL Encryption for CDH Services Добавление сервиса Hue В консоли Cloudera Manager в меню выбираем &amp;lsquo;Add Service&amp;rsquo;: Перенастройка размещения log&amp;rsquo;ов В настройках Hue, используя категорию &amp;lsquo;Logs&amp;rsquo;, изменяем следующие параметры, добавляя &amp;lsquo;/data&amp;rsquo; вместо &amp;lsquo;/var&amp;rsquo;: Нажимаем Save Changes. 4. Настройка TLS для Hue Hue как клиент TLS Hue действует как клиент TLS при взаимодействии с другими сервисами, такими как Hadoop, HBase, Oozie и Amazon S3. Это означает, что Hue должен аутентифицировать демонов HDFS, MapReduce, YARN, сервер HBase Thrift и т.</description>
    </item>
    <item>
      <title>21. Solr. Установка и настройка</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/solr-ustanovka-i-nastroyka/</link>
      <pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/solr-ustanovka-i-nastroyka/</guid>
      <description>1. Использованные материалы Configuring TLS/SSL for Solr Cloudera Search Authentication 2. Добавление сервиса Solr В консоли Cloudera Manager в меню выбираем &amp;lsquo;Add Service&amp;rsquo;: Выбираем Solr. Выбираем зависимости: Распределяем роли. Пути к каталогам оставляем без изменений: Наблюдаем запуск ролей. Визард успешно закончен. 3. Перенастройка размещения log&amp;rsquo;ов В настройках Solr, используя категорию &amp;lsquo;Logs&amp;rsquo;, изменяем следующие параметры, добавляя &amp;lsquo;/data&amp;rsquo; вместо &amp;lsquo;/var&amp;rsquo;: 2.Нажимаем Save Changes.&#xA;4. Настройка TLS Так как на данный момент в сертификатах хостов отсутствует SAN с ip-адресами узлов, то в дополнение к TLS-параметрам добавляем отключение проверки имён узлов.</description>
    </item>
    <item>
      <title>22. Kafka. Установка и настройка</title>
      <link>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/kafka-ustanovka-i-nastroyka/</link>
      <pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/manuals/bigdata/ustanovka-cloudera-cdh-6.3.2-s-tls-i-kerberos-na-osnove-freeipa/kafka-ustanovka-i-nastroyka/</guid>
      <description>2021-07-23&#xA;Добавление сервиса Kafka В консоли Cloudera Manager в меню выбираем &amp;lsquo;Add Service&amp;rsquo;: Выбираем Kafka. Выбираем зависимости: Распределяем роли с некоторыми условиями: Из-за особенностей работы, которая приводит к высокой утилизации ресурсов системы, под Kafka Brokers лучше выделить отдельные хосты. Чрезвычайно не рекомендуется размещать Kafka на ZooKeeper-узлах. Изменяем настройки: Наблюдаем запуск ролей. Визард успешно закончен. 3. Перенастройка размещения log&amp;rsquo;ов В настройках Kafka, используя категорию &amp;lsquo;Logs&amp;rsquo;, изменяем следующие параметры, добавляя &amp;lsquo;/data&amp;rsquo; вместо &amp;lsquo;/var&amp;rsquo;: Нажимаем Save Changes.</description>
    </item>
  </channel>
</rss>
